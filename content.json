{"meta":{"title":"StCat Papertimes","subtitle":"Thinking in cat's mind","description":"Thinking in cat's mind","author":"St.Cat","url":"http://stcat.top"},"pages":[{"title":"Archives","date":"2016-10-24T06:36:03.000Z","updated":"2017-12-06T13:52:25.266Z","comments":false,"path":"archives/index.html","permalink":"http://stcat.top/archives/index.html","excerpt":"","text":""},{"title":"Tags","date":"2016-10-24T06:34:45.000Z","updated":"2017-12-06T13:51:36.026Z","comments":false,"path":"tags/index.html","permalink":"http://stcat.top/tags/index.html","excerpt":"","text":""},{"title":"Categories","date":"2016-10-24T06:29:00.000Z","updated":"2017-12-06T13:51:59.077Z","comments":false,"path":"categories/index.html","permalink":"http://stcat.top/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"Javascript发布订阅模式","slug":"Javascript发布订阅模式","date":"2016-10-25T05:29:27.000Z","updated":"2017-12-06T14:57:52.766Z","comments":true,"path":"2016/10/25/Javascript发布订阅模式/","link":"","permalink":"http://stcat.top/2016/10/25/Javascript发布订阅模式/","excerpt":"发布订阅模式介绍​ 发布—订阅模式又叫观察者模式，它定义了对象间的一种一对多的关系，让多个观察者对象同时监听某一个主题对象，当一个对象发生改变时，所有依赖于它的对象都将得到通知。","text":"发布订阅模式介绍​ 发布—订阅模式又叫观察者模式，它定义了对象间的一种一对多的关系，让多个观察者对象同时监听某一个主题对象，当一个对象发生改变时，所有依赖于它的对象都将得到通知。 生活中的发布订阅模式​ 小红最近在淘宝网上看上一双鞋子，但是呢 联系到卖家后，才发现这双鞋卖光了，但是小红对这双鞋又非常喜欢，所以呢联系卖家，问卖家什么时候有货，卖家告诉她，要等一个星期后才有货，卖家告诉小红，要是你喜欢的话，你可以收藏我们的店铺，等有货的时候再通知你，所以小红收藏了此店铺，但与此同时，小明，小花等也喜欢这双鞋，也收藏了该店铺；等来货的时候就依次会通知他们； ​ 在上面的故事中，可以看出是一个典型的发布订阅模式，卖家是属于发布者，小红，小明等属于订阅者，订阅该店铺，卖家作为发布者，当鞋子到了的时候，会依次通知小明，小红等，依次使用旺旺等工具给他们发布消息； #发布订阅模式的优缺点 优点： 支持简单的广播通信，当对象状态发生改变时，会自动通知已经订阅过的对象。比如上面的列子，小明，小红不需要天天逛淘宝网看鞋子到了没有，在合适的时间点，发布者(卖家)来货了的时候，会通知该订阅者(小红，小明等人)。 发布者与订阅者耦合性降低，发布者只管发布一条消息出去，它不关心这条消息如何被订阅者使用，同时，订阅者只监听发布者的事件名，只要发布者的事件名不变，它不管发布者如何改变；同理卖家（发布者）它只需要将鞋子来货的这件事告诉订阅者(买家)，他不管买家到底买还是不买，还是买其他卖家的。只要鞋子到货了就通知订阅者即可。 ​ ​对于第1点，我们日常工作中也经常使用到，比如我们的ajax请求，请求有成功(success)和失败(error)的回调函数，我们可以订阅ajax的success和error事件。我们并不关心对象在异步运行的状态，我们只关心success的时候或者error的时候我们要做点我们自己的事情就可以了 缺点： 创建订阅者需要消耗一定的时间和内存。 虽然可以弱化对象之间的联系，如果过度使用的话，反而使代码不好理解及代码不好维护等等。 如何实现发布–订阅模式？ 首先要想好谁是发布者(比如上面的卖家)。 然后给发布者添加一个缓存列表，用于存放回调函数来通知订阅者(比如上面的买家收藏了卖家的店铺，卖家通过收藏了该店铺的一个列表名单)。 最后就是发布消息，发布者遍历这个缓存列表，依次触发里面存放的订阅者回调函数。 我们还可以在回调函数里面添加一点参数，比如鞋子的颜色，鞋子尺码等信息； 我们先来实现下简单的发布-订阅模式；代码如下： 123456789101112131415161718192021222324var shoeObj = &#123;&#125;; // 定义发布者shoeObj.list = []; // 缓存列表 存放订阅者回调函数// 增加订阅者shoeObj.listen = function(fn) &#123;trueshoeObj.list.push(fn); // 订阅消息添加到缓存列表&#125;// 发布消息shoeObj.trigger = function()&#123;truefor(var i = 0,fn; fn = this.list[i++];) &#123;truetruefn.apply(this,arguments); true&#125;&#125;// 小红订阅如下消息shoeObj.listen(function(color,size)&#123;trueconsole.log(\"颜色是：\"+color);trueconsole.log(\"尺码是：\"+size); &#125;);// 小花订阅如下消息shoeObj.listen(function(color,size)&#123;trueconsole.log(\"再次打印颜色是：\"+color);trueconsole.log(\"再次打印尺码是：\"+size); &#125;);shoeObj.trigger(\"红色\",40);shoeObj.trigger(\"黑色\",42); 运行结果：","categories":[{"name":"Program","slug":"Program","permalink":"http://stcat.top/categories/Program/"},{"name":"Javascript","slug":"Program/Javascript","permalink":"http://stcat.top/categories/Program/Javascript/"}],"tags":[{"name":"Javascript","slug":"Javascript","permalink":"http://stcat.top/tags/Javascript/"},{"name":"Design Pattern","slug":"Design-Pattern","permalink":"http://stcat.top/tags/Design-Pattern/"}]},{"title":"Trajectory_similarity_calculate","slug":"traj","date":"2016-10-25T05:29:27.000Z","updated":"2017-12-06T15:12:25.318Z","comments":true,"path":"2016/10/25/traj/","link":"","permalink":"http://stcat.top/2016/10/25/traj/","excerpt":"Alongside the benefits, AI will also bring dangers, like powerful autonomous weapons, or new ways for the few to oppress the many. Stephen Hawking www.baidu.com www.cam.ac.uk Calculate the the similarity between trajectories according to geometric features, destinations and originations. AI是把双刃剑，人类在获益的同时也面临着风险。","text":"Alongside the benefits, AI will also bring dangers, like powerful autonomous weapons, or new ways for the few to oppress the many. Stephen Hawking www.baidu.com www.cam.ac.uk Calculate the the similarity between trajectories according to geometric features, destinations and originations. AI是把双刃剑，人类在获益的同时也面临着风险。 Processing steps Traj_time_interpTo interpolate timestamp accroding to each recorded GPS point. Left Center Right aaa bbb ccc ddd eee fff Left Center Right aaa bbb ccc ddd eee fff A B 123 456 A B 12 45 Options Name Values Description input_csv path\\input.csv The csv to deal with output_csv path\\output.csv The csv to save result chunk_size 20000(default) Number of rows per read() geom_field POLYLINE Field name of geometry in the input data time_seq_field TIME_SEQ Field name of time sequence in the input data time_begin_field TIMESTAMP Field name of the begin time of each trajectory id_field TRIP_ID The unique index to distinguish each trajectory time_interval 15 The time interval between each pair of GPS points Instance 1234567891011121314from data_processing.traj_time_interp import TrajTimeInterpconfigs = dict()configs['input_csv'] = r'D:\\Document\\Geone\\Project\\#22.Trajectory\\data\\Taxi\\test.csv'configs['output_csv'] = r'D:\\time_interp.csv'configs['id_field'] = 'TRIP_ID'configs['geom_field'] = 'POLYLINE'configs['time_seq_field'] = 'TIME_SEQ'configs['time_begin_field'] = 'TIMESTAMP'configs['time_interval'] = 15configs['chunk_size'] = 20000traj_time_interp = TrajTimeInterp(**configs)traj_time_interp.interp_time() ​ Traj_transformTo transform the osm trajectory data with internal methods. Options | Name | Values | Description || ————— | :————————————— | —————————————- || input_csv | path\\input.csv | csv to deal with || output_csv | path\\output.csv | csv to save result || chunk_size | 20000(default) | number of rows per read() || geom_field | POLYLINE | field name of geometry in the input data || time_seq_field | TIME_SEQ | filed name of time sequence in the input data || methods | [“shift_fixing”,”remove_short”,”to_wkt”] | the combination of methods you want to apply to the data || shift_tolerance | 0.013(default) | largest shifted distance allowed in valid data (in degrees) || min_points | 3(default) | lines less than min_points would be dropped in the output data | Internal methods Internal method is able to assemble in a customized order within a list: | Methods | Values | Description || ———— | —————————————- | —————————————- || to_wkt | Null | format the geometry as wkt || shift_fixing | shift_tolerance | remove large shifed points beyond tolence || remove_short | min_points | remove short lines less than min_points | Instance: 1234567891011121314from data_processing.traj_transform import TrajTransformingtrans_config = dict()trans_config['input_csv'] = r'D:\\time_interp.csv'trans_config['output_csv'] = r'D:\\transformed.csv'trans_config['shift_tolerance'] = 0.013trans_config['min_points'] = 3trans_config['chunk_size'] = 10trans_config['geomfiled'] = 'POLYLINE'trans_config['time_seq_field'] = 'TIME_SEQ'trans_config['methods'] = '[\"shift_fixing\",\"remove_short\",\"to_wkt\"]'tf = TrajTransforming(**trans_config)tf.transform() Notes: remove_short() is supposed to be executed after shift_fixing() because of its removing operation. Traj_matchTo match the trajectory onto map roads by using this service and appli extractos for obtaining route infomations. Options | Name | Values | Description || —————- | :————————————— | —————————————- || input_csv | path\\input.csv | The csv to deal with || output_csv | path\\output.csv | The csv to save result || chunk_size | 20000(default) | Number of rows per read() || geom_field | POLYLINE | Field name of geometry in the input data || time_seq_field | TIME_SEQ | Filed name of time sequence in the input data || time_begin_field | TIMESTAMP | Field name of the begin time of each trajectory || server | http://192.168.34.149 | The url of matching server || port | 3000 | The port of matching server || route | match | Api route of the server || geometries | polyline (default), polyline6 , geojson | Returned route geometry format || steps | True | Returned route steps for each route || annotations | True | Returns additional metadata for each coordinate along the route geometry. || overview | simplified (default), full , false | Add overview geometry either full, simplified according to highest zoom leve || methods | [“geometry”,”turns”,”depart”,”arrive”,”edges”] | the combination of extractors you want to apply to the data | Instance: 1234567891011121314151617181920from data_processing.traj_match import TrajMatchingtraj_matching_config = &#123; 'input_csv': r'D:\\transformed.csv', 'output_csv': r'D:\\matched.csv', 'geom_field': 'POLYLINE', 'time_seq_field': 'TIME_SEQ', 'server': '192.168.34.149', 'port': '3000', 'route': 'match', 'geometries': 'geojson', 'steps': 'true', 'annotations': 'true', 'overview': 'full', 'methods': [\"geometry\",\"turns\",\"depart\",\"arrive\",\"edges\"], 'chunk_size':20000 &#125;tm = TrajMatching(**traj_matching_config)tm.matching() Feature_extractionTo do something… AnalysisTo do somethings… Assist###Processing The processing is the base class of all data processing classed, supporting some basic operation, like data loading, data saving and so on. Log_progressThe log_progess.py is designed for output the progess of process the during the programe running. Instance: 1234567from assist.log_progess import LogProgressdef process_task(): progress = LogProgress(len(task),5 ) # scale= len(task), interval = 5% for i in task: # do something progress.next() Output: 1234process_task: 5%process_task: 10%...process_task: 100% Pg_operationThe pg_operation.py is designed for connecting, querying and operation the postgressql db. Instance: 1234567891011121314151617181920212223from sql.pg_operation import PgOperationdb_config = dict()db_config['database'] = 'pg_spatial'db_config['user'] = 'postgres'db_config['password'] = '123'db_config['host'] = '127.0.0.1'db_config['port'] = '5432'db_config['buffer_size'] = 100 # optional: which point out how many sqls per committingdb = PgOperation(**db_config)sql = 'select * from tbl'data = db.query2Dict(sql) # data:[&#123;'name':'sarah',age:12&#125;,&#123;'name':'lucas',age:27&#125;...]sql = 'UPDATE tbl SET col1 = \"NULL\"'db.executeSQL(sql)sql = 'INSERT INTO tbl (col1, col2) VALUES(%(val1)s, %(val2)s)'params = &#123; 'val1':1 'val2':2&#125;db.executeSQL(sql)","categories":[{"name":"Python","slug":"Python","permalink":"http://stcat.top/categories/Python/"}],"tags":[{"name":"trajectory","slug":"trajectory","permalink":"http://stcat.top/tags/trajectory/"},{"name":"trajecotry similartiry","slug":"trajecotry-similartiry","permalink":"http://stcat.top/tags/trajecotry-similartiry/"},{"name":"map matching","slug":"map-matching","permalink":"http://stcat.top/tags/map-matching/"}]},{"title":"Hiker主题预览","slug":"Hiker主题预览","date":"2016-10-24T03:07:20.000Z","updated":"2017-01-11T18:24:34.000Z","comments":true,"path":"2016/10/24/Hiker主题预览/","link":"","permalink":"http://stcat.top/2016/10/24/Hiker主题预览/","excerpt":"Hiker主题预览Hiker is an attractive theme for Hexo. called “Hiker”, short for “HikerNews”.","text":"Hiker主题预览Hiker is an attractive theme for Hexo. called “Hiker”, short for “HikerNews”.","categories":[{"name":"Hexo","slug":"Hexo","permalink":"http://stcat.top/categories/Hexo/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://stcat.top/tags/Hexo/"}]},{"title":"【Machine Learning】机器学习：简明入门指南","slug":"【Machine Learning】机器学习：简明入门指南","date":"2016-08-14T09:32:55.000Z","updated":"2017-01-11T18:24:34.000Z","comments":true,"path":"2016/08/14/【Machine Learning】机器学习：简明入门指南/","link":"","permalink":"http://stcat.top/2016/08/14/【Machine Learning】机器学习：简明入门指南/","excerpt":"本文是一篇转载自伯乐在线的译文，英文原文是这里：Machine Learning is Fun! — by Adam Geitgey 在听到人们谈论机器学习的时候，你是不是对它的涵义只有几个模糊的认识呢？你是不是已经厌倦了在和同事交谈时只能一直点头？让我们改变一下吧！ 本指南的读者对象是所有对机器学习有求知欲但却不知道如何开头的朋友。我猜很多人已经读过了“机器学习” ——维基百科词条，倍感挫折，以为没人能给出一个高层次的解释。本文就是你们想要的东西。 本文目标在于平易近人，这意味着文中有大量的概括。但是谁在乎这些呢？只要能让读者对于ML更感兴趣，任务也就完成了。","text":"本文是一篇转载自伯乐在线的译文，英文原文是这里：Machine Learning is Fun! — by Adam Geitgey 在听到人们谈论机器学习的时候，你是不是对它的涵义只有几个模糊的认识呢？你是不是已经厌倦了在和同事交谈时只能一直点头？让我们改变一下吧！ 本指南的读者对象是所有对机器学习有求知欲但却不知道如何开头的朋友。我猜很多人已经读过了“机器学习” ——维基百科词条，倍感挫折，以为没人能给出一个高层次的解释。本文就是你们想要的东西。 本文目标在于平易近人，这意味着文中有大量的概括。但是谁在乎这些呢？只要能让读者对于ML更感兴趣，任务也就完成了。 何为机器学习？机器学习这个概念认为，对于待解问题，你无需编写任何专门的程序代码，遗传算法（generic algorithms）能够在数据集上为你得出有趣的答案。对于遗传算法，不用编码，而是将数据输入，它将在数据之上建立起它自己的逻辑。 举个例子，有一类算法称为分类算法，它可以将数据划分为不同的组别。一个用来识别手写数字的分类算法，不用修改一行代码，就可以用来将电子邮件分为垃圾邮件和普通邮件。算法没变，但是输入的训练数据变了，因此它得出了不同的分类逻辑。 机器学习算法是个黑盒，可以重用来解决很多不同的分类问题。 “机器学习”是一个涵盖性术语，覆盖了大量类似的遗传算法。 两类机器学习算法你可以认为机器学习算法分为两大类：监督式学习（Supervised Learning）和非监督式学习（Unsupervised Learning）。两者区别很简单，但却非常重要。 监督式学习假设你是一名房产经纪，生意越做越大，因此你雇了一批实习生来帮你。但是问题来了——你可以看一眼房子就知道它到底值多少钱，实习生没有经验，不知道如何估价。 为了帮助你的实习生（也许是为了解放你自己去度个假），你决定写个小软件，可以根据房屋大小、地段以及类似房屋的成交价等因素来评估你所在地区房屋的价值。 你把3个月来城里每笔房屋交易都写了下来，每一单你都记录了一长串的细节——卧室数量、房屋大小、地段等等。但最重要的是，你写下了最终的成交价： 这是我们的“训练数据”: 我们要利用这些训练数据来编写一个程序来估算该地区其他房屋的价值： 这就称为监督式学习。你已经知道每一栋房屋的售价，换句话说，你知道问题的答案，并可以反向找出解题的逻辑。 为了编写软件，你将包含每一套房产的训练数据输入你的机器学习算法。算法尝试找出应该使用何种运算来得出价格数字。 这就像是算术练习题，算式中的运算符号都被擦去了：天哪！一个阴险的学生将老师答案上的算术符号全擦去了。 看了这些题，你能明白这些测验里面是什么样的数学问题吗？你知道，你应该对算式左边的数字“做些什么”以得出算式右边的答案。 在监督式学习中，你是让计算机为你算出数字间的关系。而一旦你知道了解决这类特定问题所需要的数学方法后，你就可以解答同类的其它问题了。 非监督式学习让我们回到开头那个房地产经纪的例子。要是你不知道每栋房子的售价怎么办？即使你所知道的只是房屋的大小、位置等信息，你也可以搞出很酷的花样。这就是所谓的非监督式学习。 即使你不是想去预测未知的数据（如价格），你也可以运用机器学习完成一些有意思的事。 这就有点像有人给你一张纸，上面列出了很多数字，然后对你说:“我不知道这些数字有什么意义，也许你能从中找出规律或是能将它们分类，或是其它什么-祝你好运！” 你该怎么处理这些数据呢？首先，你可以用个算法自动地从数据中划分出不同的细分市场。也许你会发现大学附近的买房者喜欢户型小但卧室多的房子，而郊区的买房者偏好三卧室的大户型。这些信息可以直接帮助你的营销。 你还可以作件很酷的事，自动找出房价的离群数据，即与其它数据迥异的值。这些鹤立鸡群的房产也许是高楼大厦，而你可以将最优秀的推销员集中在这些地区，因为他们的佣金更高。 本文余下部分我们主要讨论监督式学习，但这并不是因为非监督式学习用处不大或是索然无味。实际上，随着算法改良，不用将数据和正确答案联系在一起，因此非监督式学习正变得越来越重要。 老学究请看:还有很多其它种类的机器学习算法。但初学时这样理解不错了。 太酷了，但是评估房价真能被看作“学习”吗？作为人类的一员，你的大脑可以应付绝大多数情况，并且没有任何明确指令也能够学习如何处理这些情况。如果你做房产经纪时间很长，你对于房产的合适定价、它的最佳营销方式以及哪些客户会感兴趣等等都会有一种本能般的“感觉”。强人工智能（Strong AI）研究的目标就是要能够用计算机复制这种能力。 但是目前的机器学习算法还没有那么好——它们只能专注于非常特定的、有限的问题。也许在这种情况下，“学习”更贴切的定义是“在少量范例数据的基础上找出一个等式来解决特定的问题”。 不幸的是，“机器在少量范例数据的基础上找出一个等式来解决特定的问题”这个名字太烂了。所以最后我们用“机器学习”取而代之。 当然，要是你是在50年之后来读这篇文章，那时我们已经得出了强人工智能算法，而本文看起来就像个老古董。未来的人类，你还是别读了，叫你的机器仆人给你做份三明治吧。 让我们写代码吧!前面例子中评估房价的程序，你打算怎么写呢？往下看之前，先思考一下吧。 如果你对机器学习一无所知，很有可能你会尝试写出一些基本规则来评估房价，如下： 123456789101112131415161718192021222324252627def estimate_house_sales_price(num_of_bedrooms, sqft, neighborhood): price = 0 # In my area, the average house costs $200 per sqft price_per_sqft = 200 if neighborhood == \"hipsterton\": # but some areas cost a bit more price_per_sqft = 400 elif neighborhood == \"skid row\": # and some areas cost less price_per_sqft = 100 # start with a base price estimate based on how big the place is price = price_per_sqft * sqft # now adjust our estimate based on the number of bedrooms if num_of_bedrooms == 0: # Studio apartments are cheap price = price — 20000 else: # places with more bedrooms are usually # more valuable price = price + (num_of_bedrooms * 1000) return price 假如你像这样瞎忙几个小时，也许会取得一点成效，但是你的程序永不会完美，而且当价格变化时很难维护。 如果能让计算机找出实现上述函数功能的办法，这样岂不更好？只要返回的房价数字正确，谁会在乎函数具体干了些什么呢？ 1234def estimate_house_sales_price(num_of_bedrooms, sqft, neighborhood): price = &lt;computer, plz do some math for me&gt; return price 考虑这个问题的一种角度是将房价看做一碗美味的汤，而汤中成分就是卧室数、面积和地段。如果你能算出每种成分对最终的价格有多大影响，也许就能得到各种成分混合起来形成最终价格的具体比例。 这样可以将你最初的程序（全是疯狂的if else语句）简化成类似如下的样子： 12345678910111213141516def estimate_house_sales_price(num_of_bedrooms, sqft, neighborhood): price = 0 # a little pinch of this price += num_of_bedrooms * .841231951398213 # and a big pinch of that price += sqft * 1231.1231231 # maybe a handful of this price += neighborhood * 2.3242341421 # and finally, just a little extra salt for good measure price += 201.23432095 return price 请注意那些用粗体标注的神奇数字——.841231951398213, 1231.1231231,2.3242341421, 和201.23432095。它们称为权重。如果我们能找出对每栋房子都适用的完美权重，我们的函数就能预测所有的房价！ 找出最佳权重的一种笨办法如下所示： 步骤1：首先，将每个权重都设为1.0： 12345678910111213141516def estimate_house_sales_price(num_of_bedrooms, sqft, neighborhood): price = 0 # a little pinch of this price += num_of_bedrooms * 1.0 # and a big pinch of that price += sqft * 1.0 # maybe a handful of this price += neighborhood * 1.0 # and finally, just a little extra salt for good measure price += 1.0 return price 步骤2：将每栋房产带入你的函数运算，检验估算值与正确价格的偏离程度： 运用你的程序预测房屋价格。 例如：上表中第一套房产实际成交价为25万美元，你的函数估价为17.8万，这一套房产你就差了7.2万。 再将你的数据集中的每套房产估价偏离值平方后求和。假设数据集中有500套房产交易，估价偏离值平方求和总计为86,123,373美元。这就反映了你的函数现在的“正确”程度。 现在，将总计值除以500，得到每套房产的估价偏离平均值。将这个平均误差值称为你函数的代价。 如果你能调整权重使得这个代价变为0，你的函数就完美了。它意味着，根据输入的数据，你的程序对每一笔房产交易的估价都是分毫不差。而这就是我们的目标——尝试不同的权重值以使代价尽可能的低。 步骤3：不断重复步骤2，尝试所有可能的权重值组合。哪一个组合使得代价最接近于0，它就是你要使用的，你只要找到了这样的组合，问题就得到了解决! 思想扰动时间这太简单了，对吧？想一想刚才你做了些什么。你取得了一些数据，将它们输入至三个通用的简单步骤中，最后你得到了一个可以对你所在区域的房屋进行估价的函数。房价网，要当心咯！但是下面的事实可能会扰乱你的思想： 1.过去40年来，很多领域（如语言学/翻译学）的研究表明，这种通用的“搅动数据汤”（我编造的词）式的学习算法已经胜过了需要利用真人明确规则的方法。机器学习的“笨”办法最终打败了人类专家。 2.你最后写出的函数真是笨，它甚至不知道什么是“面积”和“卧室数”。它知道的只是搅动，改变数字来得到正确的答案。 3.很可能你都不知道为何一组特殊的权重值能起效。所以你只是写出了一个你实际上并不理解却能证明的函数。 4.试想一下，你的程序里没有类似“面积”和“卧室数”这样的参数，而是接受了一组数字。假设每个数字代表了你车顶安装的摄像头捕捉的画面中的一个像素，再将预测的输出不称为“价格”而是叫做“方向盘转动度数”，这样你就得到了一个程序可以自动操纵你的汽车了！ 太疯狂了，对吧？ 步骤3中的“尝试每个数字”怎么回事？好吧，当然你不可能尝试所有可能的权重值来找到效果最好的组合。那可真要花很长时间，因为要尝试的数字可能无穷无尽。 为避免这种情况，数学家们找到了很多聪明的办法（比如Gradient descent算法）来快速找到优秀的权重值，而不需要尝试过多。下面是其中一种： 首先，写出一个简单的等式表示前述步骤2，这是你的代价函数： 接着，让我们将这同一个等式用机器学习的数学术语（现在你可以忽略它们）进行重写： θ表示当前的权重值。 J(θ) 意为“当前权重值对应的代价”。 这个等式表示我们的估价程序在当前权重值下偏离程度的大小。如果将所有赋给卧室数和面积的可能权重值以图形形式显示，我们会得到类似下图的图表： 代价函数的图形像一支碗。纵轴表示代价。 图中蓝色的最低点就是代价最低的地方——即我们的程序偏离最小。最高点意味着偏离最大。所以，如果我们能找到一组权重值带领我们到达图中的最低点，我们就找到了答案！ 因此，我们只需要调整权重值使我们在图上能向着最低点“走下坡路”。如果对于权重的细小调节能一直使我们保持向最低点移动，那么最终我们不用尝试太多权重值就能到达那里。 如果你还记得一点微积分的话，你也许记得如果你对一个函数求导，结果会告诉你函数在任一点的斜率。换句话说，对于图上给定一点，它告诉我们那条路是下坡路。我们可以利用这一点朝底部进发。 所以，如果我们对代价函数关于每一个权重求偏导，那么我们就可以从每一个权重中减去该值。这样可以让我们更加接近山底。一直这样做，最终我们将到达底部，得到权重的最优值。（读不懂？不用担心，接着往下读）。 这种找出最佳权重的办法被称为批量梯度下降，上面是对它的高度概括。如果想搞懂细节，不要害怕，继续深入下去吧。 当你使用机器学习算法库来解决实际问题，所有这些都已经为你准备好了。但明白一些具体细节总是有用的。 还有什么你随便就略过了？上面我描述的三步算法被称为多元线性回归。你估算等式是在求一条能够拟合所有房价数据点的直线。然后，你再根据房价在你的直线上可能出现的位置用这个等式来估算从未见过的房屋的价格。这个想法威力强大，可以用它来解决“实际”问题。 但是，我为你展示的这种方法可能在简单的情况下有效，它不会在所有情况下都有用。原因之一是因为房价不会一直那么简单地跟随一条连续直线。 但是，幸运的是，有很多办法来处理这种情况。对于非线性数据，很多其他类型的机器学习算法可以处理（如神经网络或有核向量机）。还有很多方法运用线性回归更灵活，想到了用更复杂的线条来拟合。在所有的情况中，寻找最优权重值这一基本思路依然适用。 还有，我忽略了过拟合的概念。很容易碰上这样一组权重值，它们对于你原始数据集中的房价都能完美预测，但对于原始数据集之外的任何新房屋都预测不准。这种情况的解决之道也有不少（如正则化以及使用交叉验证数据集）。学会如何处理这一问题对于顺利应用机器学习至关重要。 换言之，基本概念非常简单，要想运用机器学习得到有用的结果还需要一些技巧和经验。但是，这是每个开发者都能学会的技巧。 机器学习法力无边吗？一旦你开始明白机器学习技术很容易应用于解决貌似很困难的问题（如手写识别），你心中会有一种感觉，只要有足够的数据，你就能够用机器学习解决任何问题。只需要将数据输入进去，就能看到计算机变戏法一样找出拟合数据的等式。 但是很重要的一点你要记住，机器学习只能对用你占有的数据实际可解的问题才适用。 例如，如果你建立了一个模型来根据每套房屋内盆栽数量来预测房价，它就永远不会成功。房屋内盆栽数量和房价之间没有任何的关系。所以，无论它怎么去尝试，计算机也推导不出两者之间的关系。 你只能对实际存在的关系建模。 怎样深入学习机器学习我认为，当前机器学习的最大问题是它主要活跃于学术界和商业研究组织中。对于圈外想要有个大体了解而不是想成为专家的人们，简单易懂的学习资料不多。但是这一情况每一天都在改善。 吴恩达教授（Andrew Ng）在Coursera上的机器学习免费课程非常不错。我强烈建议由此入门。任何拥有计算机科学学位、还能记住一点点数学的人应该都能理解。 另外，你还可以下载安装SciKit-Learn，用它来试验成千上万的机器学习算法。它是一个python框架，对于所有的标准算法都有“黑盒”版本。","categories":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://stcat.top/categories/Machine-Learning/"}],"tags":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://stcat.top/tags/Machine-Learning/"}]},{"title":"BAT人才体系的职位层级、薪酬、晋升标准","slug":"BAT人才体系的职位层级、薪酬、晋升标准大全","date":"2016-08-02T03:06:00.000Z","updated":"2017-01-11T18:24:34.000Z","comments":true,"path":"2016/08/02/BAT人才体系的职位层级、薪酬、晋升标准大全/","link":"","permalink":"http://stcat.top/2016/08/02/BAT人才体系的职位层级、薪酬、晋升标准大全/","excerpt":"互联网圈有这么一句话：百度的技术，阿里的运营，腾讯的产品。那么代表互联网三座大山的BAT，内部人才体系有什么区别呢？可以先看看这个话题百度、腾讯和阿里内部的级别和薪资待遇是什么样的？ ★ 腾讯 ★1、职级腾讯职级体系分6级，最低1级，最高6级。同时按照岗位又划分为四大通道，内部也叫“族”，比如： 产品/项目通道，简称P族技术通道，简称T族市场通道，简称M族职能通道，简称S族 以T族为例，分别为： T1：助理工程师 （一般为校招新人） T2：工程师 T3：高级工程师 3-1相当于阿里的p6+到p7（能力强可能到p7） T4：专家工程师 T5：科学家 T6：首席科学家","text":"互联网圈有这么一句话：百度的技术，阿里的运营，腾讯的产品。那么代表互联网三座大山的BAT，内部人才体系有什么区别呢？可以先看看这个话题百度、腾讯和阿里内部的级别和薪资待遇是什么样的？ ★ 腾讯 ★1、职级腾讯职级体系分6级，最低1级，最高6级。同时按照岗位又划分为四大通道，内部也叫“族”，比如： 产品/项目通道，简称P族技术通道，简称T族市场通道，简称M族职能通道，简称S族 以T族为例，分别为： T1：助理工程师 （一般为校招新人） T2：工程师 T3：高级工程师 3-1相当于阿里的p6+到p7（能力强可能到p7） T4：专家工程师 T5：科学家 T6：首席科学家 目前全腾讯貌似就一个T6。 每一级之间又分为3个子级，3-1是任命组长/副组长的必要条件，其他线也是这样。T4基本为总监级，也不排除有T3-3的总监，因为T4非常难晋级。 2、晋升腾讯的晋级还是很困难的。尤其是T2 升T3，T3升T4。非常多的人卡在2-3,3-3没办法晋级。有的小伙伴做了3、4年的2-3 也升不上去啊。 3、薪水腾讯薪资架构：12+1+1=14薪 年终奖：看部门盈利情况，一般是3个月 职级待遇基本如下(2015年左右)： 级别越高base薪酬也越高，一年根据你的performance大概能发15.3个月至18个月的工资，T3.1的base 2w+，T3以上级别的员工都会有股票期权，腾讯09以前的员工赚钱主要靠股票，从08到现在股票up了500%+，T5+的base薪酬在600w~800w/年。 4、人才人才流动的可能： 深圳：很多腾讯员工都买了房，当你的房子，妻子的工作，儿子的学校，你的朋友圈，都在一个城市的时候，换城市就有困难了。所以只能挖一些比较浅的人走。 北京：人数不少 ，不过骨干员工不多。腾讯视频的主要团队在北京的倒是不少。 成都、大连：在这些二线城市，腾讯就是当地最好的互联网公司了，提供的待遇也是非常高的，不少人都对自己的薪资比较满意，工作环境也很满意。跳槽的可能性低了很多。 人才结构： 腾讯的研发序列硕士学历的占多度，211大学，985大学占多数。大家都知道腾讯研究院解散了。去年走出来很多人，腾讯人才创业比例不高。 在腾讯最常碰到的晋升问题就是天花板。可能新人进去，学东西会很多，但业务线就这些，没有那么多坑，自然也就很难晋升高级岗。 在腾讯最悲剧的时刻就是公司有收购和整合。搜狗合并，搜搜的人哭了，京东合作，易迅的人哭了。在腾讯跳出来碰到最大的问题就是，外面的公司太不完善了。 ★ 阿里巴巴 ★1、层级阿里的职称大部分都归纳在P序列 ,你的title+工种。比如P7产品经理=产品专家。 一般到P3为助理 P4=专员 P5=资深专员 P6=高级专员（也可能是高级资深） P7=专家 P8=资深专家（架构师） P9=高级专家（资深架构师） P10=研究员 P11=高级研究员 P12=科学家 P13=首席科学家 P14=马云 同时对应P级还有一套管理层的机制在： M1=P6 主管 M2=P7 经理 M3=P8 资深经理 M4 =P9 总监 M5= P10 资深总监 M6 =P11 副总裁 M7=P12 资深副总裁 M8=P13 子公司CEO 或集团其他O M9=P14 陆兆禧（前马云） 在阿里早些时候P级普遍偏低，专员可能是P2这样，后来有了一次P级通货膨胀，出现了更多的P级。在阿里只有P6（M1）后才算是公司的中层。不同的子公司给出P级的标准不一样。 比如：B2B的普遍P级较高，但是薪资水平低于天猫子公司的同级人员。同时到达该P级员工才有享受公司RSU的机会。（低于P6的除非项目出色有RSU奖励，否则1股都拿不到） 2、晋升晋升很简单： 晋升资格：上年度KPI达3.75。 主管提名。一般KPI不达3.75主管不会提名。 晋升委员会面试。（晋升委员会组成一般是合作方业务部门大佬、HRG、该业务线大佬等。） 晋升委员会投票。 P5升P6相对容易，再往上会越来越难，一般到P7都是团队技术leader了，P6到P7非常难，从员工到管理的那一步跨出去不容易，当然有同学说P一般都是专家，M才是管理，actually，专家线/管理线有时并不是分的那么清楚的。 3、薪水• 阿里薪资结构：一般是12+1+3=16薪 • 年底的奖金为0-6个月薪资，90%人可拿到3个月 • 股票是工作满2年才能拿，第一次拿50%，4年能全部拿完 ★ 百度 ★1、层级百度的级别架构分成四条线。 技术序列 T：T3 - T11 （一般对应阿里高一级序列，如：百度T3=阿里P4，T5/T6属于部门骨干，非常抢手，人人猎中相当一部分offer人选都来自这个序列） 产品运营序列 P：p3-P11 （产品和运营岗，对应阿里高1-1.5级序列 百度p3=阿里P4-P5之间) 后勤支持部门 S ：S3-S11 (主要是公共、行政、渠道等等，晋升比较困难) 管理序列 M：M1-M5 (每一级又分为2个子级 M1A、M1B , 最低的是M1A，至少是部门二把手了，李明远是M3.2，以前的汤和松都是这个级别，李彦宏是唯一的M5，其实从M3开始就有机会加入E——star，类似于阿里的合伙人会议，属于最高战略决策层。 2、薪资月薪14.6（12+0.6+2）,其他岗位：月薪14 T5以上为关键岗位，另外有股票、期权。T5、T6占比最大的级别，T8、T9占比最小，级别越高，每档之间的宽幅越大。 3、晋升基本上应届毕业生应该是T3，但是内部晋升非常激烈。公司那么大，部门和部门之间有业务竞争，肯定也有人才竞争。 通常应届毕业生入职1年多能升到T4，但如果你的部门业务足够核心，或许1年就可以了。3年升T5。从目前百度的情况来看，核心工程师集中在T5/6，但是从5/6到7是非常艰难的过程。 百度是很唯KPI至上的，其次部门很核心，再次老大话语权比较高，相对晋升容易些。 一般情况分2种： 自己提名，当你自己觉得已经具备下一level的素质，可以自己提名，提名后进入考察期，主管设定考察期目标，考察通过顺利晋升，考察不通过维持原层级不变； 主管提名，如果是主管提名，一般都是直接通过的，但是如果你现层级已经比较高了，那就不是直接提名这么简单了。 P.S.如果你能升到T7，基本上是TL的级别，写代码/直接做业务的时间就很少了。","categories":[{"name":"BAT","slug":"BAT","permalink":"http://stcat.top/categories/BAT/"}],"tags":[{"name":"BAT","slug":"BAT","permalink":"http://stcat.top/tags/BAT/"}]}]}